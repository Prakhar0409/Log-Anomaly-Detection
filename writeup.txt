Preprocessing Logs:-
First, we separated each log file into by the output of commands run in it. We identified lines having commands as ones starting with the prompt i.e. "<", having a command starting with "Z" and the line ending by ";". We extracted all outputs of the same  command from the set of golden logs and created the files <Command Name>_<File Type>.txt. Thus the outputs of same command present in SWU_0.txt, SWU_1.txt etc will be in same file. We call these preprocessed files.

Processing Logs:-
We created some regex using domain knowledge of general logs to eliminate informaion that might be redundant or might not be able to help us in finding anomalies. We took the following steps:-
- Relpaced IP adresses by "rx_ip"
- Replaced dates and times by "rx_date" and "rx_time"
- Removed the hexadecimal numbers which represented various encoded messages
- Replaces User Ids and Profile Names
etc.

This allowed us to ignore the variation in these unimportant values among logs.

Next we applied an online parsing algorithm on each of these files to get a list of log sentence templates in these files. The motivation is to find the types of sentences (templates) appearing in the logs. The parser tries to identify the constant and variable part in each of the lines in log file. It then creates templates like "VLAN UP rx_num LIM *". Here * is the variable part, that the parser found to be chaging across many instances of this log line.

The algorithm we use for parsing logs, creates trees, with leafs of trees as log groups. Whenever we encounter a new log line, we try to match it with a log group at one of the leaves. If one of the log group matches with a similarity over a threshold, this log is added to it, else a new log group is added to it. The inner nodes of the tree are to simply reduce search space while searching for log group by dividing them into groups based on log length, first token of the log etc. This approch is based on the DRAIN log parser.


Finding Anomalies:-
When an anomaly occurs, we expect the log to have lines which are different than the ones. Thus if we were to preprocess it as above and run the log parser on these files to get the templates, we expect it to generate new kinds of templates that are not present in the templates generated by Golden Log files. These new templates would be creatd due to presence of new words or numbers, which were absent in Golden Logs. Thus we classify these newly created templates as anomalies.
Next we find the log lines in the original test files that match these new templates and output them as the anomalous log lines.
